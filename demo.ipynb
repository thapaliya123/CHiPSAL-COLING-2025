{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import config\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/taskb/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = df_train[df_train.label == 0]\n",
    "class_1 = df_train[df_train['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    16805\n",
       "1     2214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0 = class_0.sample(int(len(class_0) * .5), random_state=config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([class_0, class_1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    8402\n",
       "1    2214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    3602\n",
       "1     474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = pd.read_csv('./data/taskb/valid.csv')\n",
    "df_valid.label.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24488</td>\n",
       "      <td>#NoNotAgain ‡§≠‡§®‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§π‡•ã ?\\r\\n‡§Ü‡§´‡•Å‡§≤‡•á ‡§¨‡•Å‡§ù‡•á‡§ï‡•ã 1 ‡§∂‡§¨...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10846</td>\n",
       "      <td>‡§¨‡§ø‡§ú‡§®‡•å‡§∞ ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á CM ‡§Ø‡•ã‡§ó‡•Ä, ‡§ï‡§π‡§æ- '‡§¶‡§Ç‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ '‡§¶...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28186</td>\n",
       "      <td>‡§ì‡§ñ‡§≤‡§¢‡•Å‡§Ç‡§ó‡§æ, ‡§ö‡§Æ‡•ç‡§™‡§æ‡§¶‡•á‡§µ‡•Ä ‡§ó‡§æ‡§â‡§Å‡§™‡§æ‡§≤‡§ø‡§ï‡§æ\\r\\n‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§®‡•á...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10158</td>\n",
       "      <td>@anamikamber ‡§Æ‡•à‡§Ç ‡§∏‡§≠‡•Ä ‡§∏‡•á ‡§Ö‡§™‡•Ä‡§≤ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Å ‡§ï‡§ø ‡§Ü‡§≤‡§∏ ‡§õ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15821</td>\n",
       "      <td>‡§™‡§Ç‡§ú‡§æ‡§¨ ‡§ï‡•á ‡§ö‡•Å‡§®‡§æ‡§µ‡•Ä ‡§¶‡§Ç‡§ó‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§§‡§∞‡•á #ArvindKejriwal,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>36961</td>\n",
       "      <td>üëÜüèº \\r\\n‡§∂‡•á‡§∞‡§¨‡§π‡§æ‡§¶‡•Å‡§∞ ‡§¶‡•á‡§â‡§µ‡§æ‡§ï‡•ã ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Ü‡§§‡§Ç‡§ï‡§æ‡§∞‡•Ä ‡§≠‡§®‡•ç‡§¶‡•à...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>36994</td>\n",
       "      <td>‚Äò‡§™‡•ç‡§∞‡§ö‡§£‡•ç‡§°, ‡§¶‡•á‡§â‡§µ‡§æ ‡§∞ ‡§®‡•á‡§™‡§æ‡§≤ ‡§∏‡§∞‡•ç‡§™, ‡§≠‡•ç‡§Ø‡§æ‡§ó‡•Å‡§§‡•ã ‡§∞ ‡§ï‡§ø‡§•‡•ç‡§∞...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>37107</td>\n",
       "      <td>‡§µ‡§æ‡§∏‡•ç‡§§‡§¨‡§Æ‡§æ ‡§Ø‡•ã ‡§ó‡§†‡§¨‡§®‡•ç‡§ß‡§® ‡§≤‡•á ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§∞‡•ç‡§§‡§æ ‡§∞ ‡§ú...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>37149</td>\n",
       "      <td>‡§™‡§§‡§®‡§ï‡•ã ‡§¨‡§æ‡§ü‡•ã‡§Æ‡§æ ‡§π‡§ø‡§°‡•á‡§ï‡•ã ‡§ï‡§•‡§ø‡§§ \"‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§ñ‡§¨‡§∞\" ‡§∞ \"‡§è‡§Æ‡§æ‡§≤‡•á...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>37157</td>\n",
       "      <td>‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§ï‡§æ‡§ô‡•ç‡§ó‡•ç‡§∞‡•á‡§∏‡§≤‡•á ‡§µ‡§°‡§æ ‡§∏‡§¶‡§∏‡•ç‡§Ø‡§Æ‡§æ ‡§â‡§†‡•ç‡§® 1.5 ‡§≤‡§æ‡§ñ ‡§∏‡§Æ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2275 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                              tweet  label\n",
       "0     24488  #NoNotAgain ‡§≠‡§®‡•ç‡§Ø‡§æ ‡§ï‡•á ‡§π‡•ã ?\\r\\n‡§Ü‡§´‡•Å‡§≤‡•á ‡§¨‡•Å‡§ù‡•á‡§ï‡•ã 1 ‡§∂‡§¨...      0\n",
       "1     10846  ‡§¨‡§ø‡§ú‡§®‡•å‡§∞ ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á CM ‡§Ø‡•ã‡§ó‡•Ä, ‡§ï‡§π‡§æ- '‡§¶‡§Ç‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§¶ '‡§¶...      0\n",
       "2     28186  ‡§ì‡§ñ‡§≤‡§¢‡•Å‡§Ç‡§ó‡§æ, ‡§ö‡§Æ‡•ç‡§™‡§æ‡§¶‡•á‡§µ‡•Ä ‡§ó‡§æ‡§â‡§Å‡§™‡§æ‡§≤‡§ø‡§ï‡§æ\\r\\n‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§®‡•á...      0\n",
       "3     10158  @anamikamber ‡§Æ‡•à‡§Ç ‡§∏‡§≠‡•Ä ‡§∏‡•á ‡§Ö‡§™‡•Ä‡§≤ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Å ‡§ï‡§ø ‡§Ü‡§≤‡§∏ ‡§õ...      0\n",
       "4     15821  ‡§™‡§Ç‡§ú‡§æ‡§¨ ‡§ï‡•á ‡§ö‡•Å‡§®‡§æ‡§µ‡•Ä ‡§¶‡§Ç‡§ó‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§§‡§∞‡•á #ArvindKejriwal,...      0\n",
       "...     ...                                                ...    ...\n",
       "2270  36961  üëÜüèº \\r\\n‡§∂‡•á‡§∞‡§¨‡§π‡§æ‡§¶‡•Å‡§∞ ‡§¶‡•á‡§â‡§µ‡§æ‡§ï‡•ã ‡§∏‡§∞‡§ï‡§æ‡§∞‡§≤‡•á ‡§Ü‡§§‡§Ç‡§ï‡§æ‡§∞‡•Ä ‡§≠‡§®‡•ç‡§¶‡•à...      1\n",
       "2271  36994  ‚Äò‡§™‡•ç‡§∞‡§ö‡§£‡•ç‡§°, ‡§¶‡•á‡§â‡§µ‡§æ ‡§∞ ‡§®‡•á‡§™‡§æ‡§≤ ‡§∏‡§∞‡•ç‡§™, ‡§≠‡•ç‡§Ø‡§æ‡§ó‡•Å‡§§‡•ã ‡§∞ ‡§ï‡§ø‡§•‡•ç‡§∞...      1\n",
       "2272  37107  ‡§µ‡§æ‡§∏‡•ç‡§§‡§¨‡§Æ‡§æ ‡§Ø‡•ã ‡§ó‡§†‡§¨‡§®‡•ç‡§ß‡§® ‡§≤‡•á ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ‡§ø‡§ï ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡§∞‡•ç‡§§‡§æ ‡§∞ ‡§ú...      1\n",
       "2273  37149  ‡§™‡§§‡§®‡§ï‡•ã ‡§¨‡§æ‡§ü‡•ã‡§Æ‡§æ ‡§π‡§ø‡§°‡•á‡§ï‡•ã ‡§ï‡§•‡§ø‡§§ \"‡§Ö‡§®‡§≤‡§æ‡§á‡§® ‡§ñ‡§¨‡§∞\" ‡§∞ \"‡§è‡§Æ‡§æ‡§≤‡•á...      1\n",
       "2274  37157  ‡§®‡•á‡§™‡§æ‡§≤‡•Ä ‡§ï‡§æ‡§ô‡•ç‡§ó‡•ç‡§∞‡•á‡§∏‡§≤‡•á ‡§µ‡§°‡§æ ‡§∏‡§¶‡§∏‡•ç‡§Ø‡§Æ‡§æ ‡§â‡§†‡•ç‡§® 1.5 ‡§≤‡§æ‡§ñ ‡§∏‡§Æ...      1\n",
       "\n",
       "[2275 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0 = df_valid[df_valid.label == 0]\n",
    "class_1 = df_valid[df_valid['label'] == 1]\n",
    "class_0 = class_0.sample(int(len(class_0) * .5), random_state=config.SEED)\n",
    "df_valid = pd.concat([class_0, class_1], ignore_index=True)\n",
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1801\n",
       "1     474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63175434, 2.39747064])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "compute_class_weight(class_weight='balanced',classes=np.unique(df_train.label.values), y=df_train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(config.TRAINING_FILE)\n",
    "df_valid = pd.read_csv(config.VALID_FILE)\n",
    "\n",
    "class_1 = df_train[df_train['label'] == 1]\n",
    "sample_size = len(class_1)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "class_0 = df_train[df_train['label'] == 0].sample(frac=.5, random_state=config.SEED)\n",
    "# class_0_downsampled = resample(class_0, replace=False, n_samples=sample_size, random_state=config.SEED)\n",
    "\n",
    "df_train = pd.concat([class_0, class_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2214\n",
       "1    2214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data/taskb/train.csv')\n",
    "# df_valid = pd.read_csv(config.VALID_FILE)\n",
    "\n",
    "class_0 = df_train[df_train.label == 0]\n",
    "class_1 = df_train[df_train['label'] == 1]\n",
    "\n",
    "class_0 = class_0.sample(n=len(class_1), random_state=config.SEED)\n",
    "df_train = pd.concat([class_0, class_1], ignore_index=True)\n",
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iamsumanpaudel_\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = 'aBRPLI9AR7MVcbW12i0Ia84Ms'\n",
    "consumer_secret = 'y2rXlwhwGwkc3UuHVp9zGYBfKAY0jJjbtnN2yYObEhNeS30ZFG'\n",
    "access_token = '2536718180-X5zBAOFnR8fJMFsuzWtz5CDy4tqDPubnSgcDLW7'\n",
    "access_token_secret = 'YOqOOb8DDmqDgeL6jcunfdGWCWU7XV9IEYCYaOv9hUrJ0'\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "    consumer_key, consumer_secret, access_token, access_token_secret\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# If the authentication was successful, this should print the\n",
    "# screen name / username of the account\n",
    "print(api.verify_credentials().screen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyppeteer\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: certifi>=2023 in ./venv/lib/python3.12/site-packages (from pyppeteer) (2024.8.30)\n",
      "Collecting importlib-metadata>=1.4 (from pyppeteer)\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer)\n",
      "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in ./venv/lib/python3.12/site-packages (from pyppeteer) (4.66.5)\n",
      "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting websockets<11.0,>=10.0 (from pyppeteer)\n",
      "  Downloading websockets-10.4.tar.gz (84 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting zipp>=3.20 (from importlib-metadata>=1.4->pyppeteer)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.12/site-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.12.2)\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Building wheels for collected packages: websockets\n",
      "  Building wheel for websockets (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for websockets: filename=websockets-10.4-cp312-cp312-linux_x86_64.whl size=106990 sha256=a903d4a2f5c75a12132222ef9219ec84d859b1390544aaa3ebdaf5fe54c1cf79\n",
      "  Stored in directory: /home/suman/.cache/pip/wheels/80/cf/6d/5d7e4c920cb41925a178b2d2621889c520d648bab487b1d7fd\n",
      "Successfully built websockets\n",
      "Installing collected packages: appdirs, zipp, websockets, urllib3, pyee, importlib-metadata, pyppeteer\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "Successfully installed appdirs-1.4.4 importlib-metadata-8.5.0 pyee-11.1.1 pyppeteer-2.0.0 urllib3-1.26.20 websockets-10.4 zipp-3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyppeteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyppeteer 2.0.0 requires pyee<12.0.0,>=11.0.0, but you have pyee 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain-openai langchain playwright beautifulsoup4\n",
    "\n",
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "# import dotenv\n",
    "# dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain-community) (3.10.9)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.3.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.3.9)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.1.131)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.13.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.1 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:0: RuntimeWarning: coroutine 'main' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load HTML\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loader \u001b[38;5;241m=\u001b[39m AsyncChromiumLoader([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.hamropatro.com/news/details/11503924922577737?ns=bbc.com\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:31\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/langchain_community/document_loaders/chromium.py:85\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mLazily load text content from the provided URLs.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murls:\n\u001b[0;32m---> 85\u001b[0m     html_content \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascrape_playwright\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: url}\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m Document(page_content\u001b[38;5;241m=\u001b[39mhtml_content, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community\n",
    "from langchain_community.document_loaders import AsyncChromiumLoader\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "# Load HTML\n",
    "loader = AsyncChromiumLoader([\"https://www.hamropatro.com/news/details/11503924922577737?ns=bbc.com\"])\n",
    "html = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in ./venv/lib/python3.12/site-packages (from tweepy) (2.32.3)\n",
      "Collecting requests-oauthlib<2,>=1.2.0 (from tweepy)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n",
      "Downloading tweepy-4.14.0-py3-none-any.whl (98 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.2.2 requests-oauthlib-1.3.1 tweepy-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:301: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"home_timeline(*, count, since_id, max_id, trim_user, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:341: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"mentions_timeline(*, count, since_id, max_id, trim_user, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:376: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"user_timeline(*, user_id, screen_name, since_id, count, max_id, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:426: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_favorites(*, user_id, screen_name, count, since_id, max_id, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:467: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"lookup_statuses(id, *, include_entities, trim_user, map, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:599: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_retweeter_ids(id, *, count, cursor, stringify_ids)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:634: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_retweets(id, *, count, trim_user)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:667: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_retweets_of_me(*, count, since_id, max_id, trim_user, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1055: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1157: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_lists(*, user_id, screen_name, reverse)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1202: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_list_members(*, list_id, slug, owner_screen_name, owner_id, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1299: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_list_memberships(*, user_id, screen_name, count, cursor, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1342: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_list_ownerships(*, user_id, screen_name, count, cursor)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1409: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"list_timeline( \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1460: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_list_subscribers( \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1559: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_list_subscriptions(*, user_id, screen_name, count, cursor)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1927: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_follower_ids(*, user_id, screen_name, cursor, stringify_ids, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1966: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_followers(*, user_id, screen_name, cursor, count, skip_status, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2008: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_friend_ids(*, user_id, screen_name, cursor, stringify_ids, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2047: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_friends(*, user_id, screen_name, cursor, count, skip_status, \\\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2089: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"incoming_friendships(*, cursor, stringify_ids)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2120: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"lookup_friendships(*, screen_name, user_id)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2149: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"no_retweets_friendships(*, stringify_ids)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2176: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"outgoing_friendships(*, cursor, stringify_ids)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2243: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"lookup_users(*, screen_name, user_id, include_entities, tweet_mode)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2290: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"search_users(q, *, page, count, include_entities)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2500: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_saved_searches()\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2814: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_blocked_ids(*, stringify_ids, cursor)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2846: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_blocks(*, include_entities, skip_status, cursor)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2880: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_muted_ids(*, stringify_ids, cursor)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:2911: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_mutes(*, cursor, include_entities, skip_status)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:3126: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"get_direct_messages(*, count, cursor)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:3788: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"reverse_geocode(lat, long, *, accuracy, granularity, max_results)\n",
      "/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:3829: SyntaxWarning: invalid escape sequence '\\['\n",
      "  \"\"\"search_geo(*, lat, long, query, ip, granularity, max_results)\n"
     ]
    },
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m lang \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# For Hindi\u001b[39;00m\n\u001b[1;32m     18\u001b[0m tweets \u001b[38;5;241m=\u001b[39m tweepy\u001b[38;5;241m.\u001b[39mCursor(api\u001b[38;5;241m.\u001b[39msearch_tweets, q\u001b[38;5;241m=\u001b[39mquery, lang\u001b[38;5;241m=\u001b[39mlang)\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtweet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtweets\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtweet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/cursor.py:286\u001b[0m, in \u001b[0;36mItemIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Reached end of current page, get the next page...\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_iterator)\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/cursor.py:167\u001b[0m, in \u001b[0;36mIdIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 167\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRawParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     model \u001b[38;5;241m=\u001b[39m ModelParser()\u001b[38;5;241m.\u001b[39mparse(\n\u001b[1;32m    170\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[1;32m    171\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[1;32m    172\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(\n\u001b[1;32m    175\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[1;32m    176\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[1;32m    177\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_list\n\u001b[1;32m     45\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_type\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:1146\u001b[0m, in \u001b[0;36mAPI.search_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;129m@pagination\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;129m@payload\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_tweets\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    .. _Twitter's documentation on the standard search API: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearch/tweets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeocode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlang\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muntil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msince_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minclude_entities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/tweepy/api.py:271\u001b[0m, in \u001b[0;36mAPI.request\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(resp)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(resp)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product"
     ]
    }
   ],
   "source": [
    "%pip install tweepy\n",
    "import tweepy\n",
    "\n",
    "consumer_key = 'aBRPLI9AR7MVcbW12i0Ia84Ms'\n",
    "consumer_secret = 'y2rXlwhwGwkc3UuHVp9zGYBfKAY0jJjbtnN2yYObEhNeS30ZFG'\n",
    "access_token = '2536718180-X5zBAOFnR8fJMFsuzWtz5CDy4tqDPubnSgcDLW7'\n",
    "access_token_secret = 'YOqOOb8DDmqDgeL6jcunfdGWCWU7XV9IEYCYaOv9hUrJ0'\n",
    "# AAAAAAAAAAAAAAAAAAAAAJUXwQEAAAAAszAgSPLLLLxxfQ7efR%2FtO7MaRak%3DsZn99c4q76n4v15Kucm1nmPzZdJ2QvVRx3MOhLrgwL9mFKqIOw\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "query = \"political news\"  # You can specify a search query here if needed\n",
    "lang = \"hi\"  # For Hindi\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=query, lang=lang).items(100)\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 stacking_classifier.py --seed 42 --gpu-number 0 --best-model-dir ./models/ensemble_models --train-data-csv ./data/taskb/train.csv --valid-data-csv ./data/taskb/valid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Pipeline' from 'imblearn.combine' (/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/imblearn/combine/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load training and validation datasets\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Pipeline' from 'imblearn.combine' (/home/suman/CHIPSAL-COLING-2025/venv/lib/python3.12/site-packages/imblearn/combine/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import Pipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "# Load training and validation datasets\n",
    "df_train = pd.read_csv(config.TRAINING_FILE)\n",
    "df_valid = pd.read_csv(config.VALID_FILE)\n",
    "\n",
    "# Step 1: Define the desired sampling strategy for class 0 and class 1\n",
    "desired_distribution = {0: .4691, 1: 5308}  # Adjust based on your earlier calculation\n",
    "\n",
    "# Step 2: Combine oversampling class 0 and undersampling class 1\n",
    "# First, extract tweets and labels\n",
    "X_train = df_train['tweet'].values\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "# Create the pipeline for resampling\n",
    "resampling_pipeline = Pipeline([\n",
    "    ('oversample', RandomOverSampler(sampling_strategy={0: 6098})),  # Oversample class 0 to 6098\n",
    "    ('undersample', RandomUnderSampler(sampling_strategy=desired_distribution))  # Undersample class 1 to 6902\n",
    "])\n",
    "\n",
    "# Resample the training data\n",
    "X_resampled, y_resampled = resampling_pipeline.fit_resample(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Step 3: Create a new DataFrame with the resampled data\n",
    "df_resampled_train = pd.DataFrame({\n",
    "    'tweet': X_resampled.flatten(),  # Reshape back to original structure\n",
    "    'label': y_resampled\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    16805\n",
       "1     2214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.TRAINING_FILE)\n",
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch\n",
    "\n",
    "# Load training and validation datasets\n",
    "df_train = pd.read_csv(config.TRAINING_FILE)\n",
    "df_valid = pd.read_csv(config.VALID_FILE)\n",
    "\n",
    "# Step 1: Extract tweets and labels\n",
    "X_train = df_train['tweet'].values\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "# Step 2: Define the desired number of samples for each class\n",
    "desired_distribution = {0: 1956, 1: 2214}  # Class 0 undersampled, Class 1 kept intact\n",
    "\n",
    "# Step 3: Apply undersampling for class 0\n",
    "undersample = RandomUnderSampler(sampling_strategy=desired_distribution)\n",
    "X_resampled, y_resampled = undersample.fit_resample(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Step 4: Create a new DataFrame with the resampled data\n",
    "df_resampled_train = pd.DataFrame({\n",
    "    'tweet': X_resampled.flatten(),  # Reshape back to original structure\n",
    "    'label': y_resampled\n",
    "})\n",
    "\n",
    "# # Step 5: Create HFDataset objects for training and validation\n",
    "# train_dataset = dataset.HFDataset(\n",
    "#     tweet=df_resampled_train.tweet.values,\n",
    "#     label=df_resampled_train.label.values\n",
    "# )\n",
    "\n",
    "# valid_dataset = dataset.HFDataset(\n",
    "#     tweet=df_valid.tweet.values,  # Validation set remains untouched\n",
    "#     label=df_valid.label.values\n",
    "# )\n",
    "\n",
    "# # Step 6: Use DataLoader for batching\n",
    "# train_data_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4\n",
    "# )\n",
    "\n",
    "# valid_data_loader = torch.utils.data.DataLoader(\n",
    "#     valid_dataset, batch_size=config.VALID_BATCH_SIZE, num_workers=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    2214\n",
       "0    1956\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4170, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    16805\n",
       "1     2214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(config.TRAINING_FILE)\n",
    "df_train.label.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
